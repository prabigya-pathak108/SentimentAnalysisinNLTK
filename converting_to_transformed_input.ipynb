{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import enchant   #for spelling correction and checking\n",
    "from nltk.metrics import edit_distance  # to find the case where spelling correction is needed\n",
    "d = enchant.Dict(\"en_US\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import wordnet as wn,stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Lets define some function for replacement of common sentece use cases\n",
    "replacement_patterns = [\n",
    " (r'won\\'t', 'will not'),\n",
    " (r'can\\'t', 'cannot'),\n",
    " (r'i\\'m', 'i am'),\n",
    " (r'', ''),\n",
    " (r'wanna', 'want'),\n",
    " (r'gonna', 'going to'),\n",
    " (r'ain\\'t', 'is not'),\n",
    " (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    " (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    " (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    " (r'(\\w+)\\'s', '\\g<1> is'),\n",
    " (r'(\\w+)\\'re', '\\g<1> are'),\n",
    " (r'(\\w+)\\'d', '\\g<1> would')\n",
    "]\n",
    "patterns = [(re.compile(regex), repl) for (regex, repl) in replacement_patterns]\n",
    "\n",
    "def replace_function(text):\n",
    "    s = text\n",
    "    for (pattern, repl) in patterns:\n",
    "        s = re.sub(pattern, repl, s)\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#the following function remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    stopwords_list=stopwords.words(\"english\")\n",
    "    text_without_stopword=\"\"\n",
    "    for i in str(text).split():\n",
    "        if i not in stopwords_list:\n",
    "            text_without_stopword=text_without_stopword+\" \"+str(i).lower()\n",
    "    return text_without_stopword.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#the following function is used for spelling checking and correction\n",
    "def correct_spellings_all(text):\n",
    "    words = text.split()\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        if d.check(word):\n",
    "            corrected_words.append(word)\n",
    "        else:\n",
    "            suggestions = d.suggest(word)\n",
    "            if suggestions:\n",
    "                if (edit_distance(word,suggestions[0])>1):\n",
    "                    corrected_words.append(suggestions[0])\n",
    "                else:\n",
    "                    corrected_words.append(word)\n",
    "            else:\n",
    "                corrected_words.append(word)\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#the follwing function is used for lammetizing by finding the POS\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize_sentence(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    corrected_words = []\n",
    "    for token, tag in pos_tag(words):\n",
    "        lemma = lemmatizer.lemmatize(token, tag_map[tag[0]])\n",
    "        corrected_words.append(lemma)\n",
    "    return ' '.join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Apply preprocessing steps to the text\n",
    "    processed_text = replace_function(text)\n",
    "    processed_text = remove_stopwords(processed_text)\n",
    "    processed_text = correct_spellings_all(processed_text)\n",
    "    processed_text = lemmatize_sentence(processed_text)\n",
    "    return processed_text\n",
    "\n",
    "def expression_check(prediction_input):\n",
    "    if prediction_input == 0:\n",
    "        return \"It has Negative Sentiment.\"\n",
    "    elif prediction_input == 1:\n",
    "        return \"It has Positive Sentiment.\"\n",
    "    else:\n",
    "        return \"Invalid Statement.\"\n",
    "\n",
    "def predict_from_user_input(user_input, model, cv):\n",
    "    # Preprocess the user input\n",
    "    processed_input = preprocess_text(user_input)\n",
    "    \n",
    "    # Transform the preprocessed input into numerical features\n",
    "    input_data = cv.transform([processed_input])\n",
    "    \n",
    "    # Make predictions using the trained model\n",
    "    predicted_class = model.predict(input_data)\n",
    "\n",
    "    predicted_probabilities = model.predict_proba(input_data)\n",
    "    predicted_class_index = np.argmax(predicted_probabilities)\n",
    "    probability_predicted = model.predict_proba(input_data)\n",
    "    confidence = predicted_probabilities[0, predicted_class_index]\n",
    "    #print(probability_predicted,confidence)\n",
    "    \n",
    "    prediction_msg =expression_check(predicted_class)\n",
    "\n",
    "    return predicted_probabilities,prediction_msg\n",
    "\n",
    "# Load the saved model\n",
    "with open('sentiment_analysis_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load the CountVectorizer\n",
    "with open('cv.pkl', 'rb') as f:\n",
    "    cv = pickle.load(f)\n",
    "\n",
    "## answer is 112669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.41742857, 0.58257143]]), 'It has Positive Sentiment.')\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I am happy today and I want to dance.\"\n",
    "result = predict_from_user_input(user_input, model, cv)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112669"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "112669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel confident in my abilities; I know I can handle any challenge.\n",
      "0.04207936507936508\n",
      "0.04\n",
      "<class 'numpy.float64'>\n",
      "It has Positive Sentiment.\n",
      "----------------------------------------\n",
      "I am dissatisfied with my internet service; it's slow and unreliable.\n",
      "0.9284761904761903\n",
      "0.93\n",
      "<class 'numpy.float64'>\n",
      "It has Negative Sentiment.\n",
      "----------------------------------------\n",
      "I am feeling very stressed about my upcoming exams.\n",
      "0.9672777777777776\n",
      "0.97\n",
      "<class 'numpy.float64'>\n",
      "It has Negative Sentiment.\n",
      "----------------------------------------\n",
      "I am thrilled with my new hobby; it brings me so much joy.\n",
      "0.42445238095238097\n",
      "0.42\n",
      "<class 'numpy.float64'>\n",
      "It has Positive Sentiment.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I am extremely happy with my new car; it drives smoothly and looks fantastic.\",\n",
    "    \"I felt really disappointed with my performance in the meeting today.\",\n",
    "    \"My vacation was absolutely wonderful; I enjoyed every single day.\",\n",
    "    \"I am very frustrated with my computer; it keeps crashing and losing my work.\",\n",
    "    \"I am proud of my achievements this year; I've worked hard and it paid off.\",\n",
    "    \"I can't stand my new job; the work environment is toxic and stressful.\",\n",
    "    \"I love spending time with my family; they always make me feel happy and supported.\",\n",
    "    \"I am unhappy with my current living situation; the neighbors are too noisy.\",\n",
    "    \"My health has improved significantly, and I feel better than ever.\",\n",
    "    \"I regret my decision to move to this city; I feel lonely and out of place.\",\n",
    "    \"I am excited about my upcoming project; it's going to be a great opportunity.\",\n",
    "    \"I am worried about my financial situation; my expenses are too high.\",\n",
    "    \"I feel confident in my abilities; I know I can handle any challenge.\",\n",
    "    \"I am dissatisfied with my internet service; it's slow and unreliable.\",\n",
    "    \"I am feeling very stressed about my upcoming exams.\",\n",
    "    \"I am thrilled with my new hobby; it brings me so much joy.\",\n",
    "]\n",
    "\n",
    "\n",
    "for user_input in sentences[12:]:\n",
    "    print(user_input)\n",
    "    probabilities,result = predict_from_user_input(user_input, model, cv)\n",
    "    print(probabilities[0][0])\n",
    "    print(f\"{probabilities[0][0]:,.2f}\")\n",
    "    print(type(probabilities[0][0]))\n",
    "    print(result)\n",
    "\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enchant.Dict at 0x1d51304a4d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
